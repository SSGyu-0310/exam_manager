# AI ìë™ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ë¡œì§ ë¶„ì„

> **ëª©ì **: ë¬¸ì œ(Question)ê°€ ì–´ë–¤ ê°•ì˜(Lecture)ì— í•´ë‹¹í•˜ëŠ”ì§€ AIê°€ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ì²´ íë¦„ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
> í˜„ì¬ Docker í™˜ê²½(`.env.docker`)ì˜ ì„¤ì • ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

---

## 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ íë¦„ë„

```mermaid
flowchart TD
    START["ğŸš€ ë¶„ë¥˜ ì‹œì‘<br/>AsyncBatchProcessor.start_classification_job()"]
    
    subgraph PREP["ğŸ“‹ ì „ì²˜ë¦¬"]
        Q_LOAD["Question ë¡œë“œ<br/>question.content + choices"]
        Q_TEXT["question_text ì¡°í•©<br/>content + choices (ìµœëŒ€ 4000ì)"]
    end
    
    subgraph STAGE1["ğŸ” Stage 1: RETRIEVE â€” í›„ë³´ ê°•ì˜ ê²€ìƒ‰"]
        CACHE["LectureRetriever.refresh_cache()<br/>ì „ì²´ ê°•ì˜ ëª©ë¡ ë©”ëª¨ë¦¬ ìºì‹œ"]
        SCOPE["scope í•„í„° ì ìš©<br/>block_id / folder_id â†’ lecture_ids"]
        BM25["search_chunks_bm25()<br/>Postgres ts_rank_cd ê²€ìƒ‰"]
        AGG["aggregate_candidates()<br/>ìƒìœ„ 8ê°œ ê°•ì˜ë¡œ ì§‘ê³„"]
    end
    
    subgraph STAGE2["ğŸ”„ Stage 2: EXPAND â€” ì»¨í…ìŠ¤íŠ¸ í™•ì¥ (ì¡°ê±´ë¶€)"]
        PARENT_CHECK{"PARENT_ENABLED?<br/>(.env.docker: OFF)"}
        UNCERTAIN{"is_uncertain()?"}
        EXPAND["expand_candidates()<br/>semantic neighbors í™•ì¥"]
        SKIP_EXPAND["í™•ì¥ ì—†ì´ í†µê³¼"]
    end
    
    subgraph STAGE3["ğŸ¤– Stage 3: JUDGE â€” LLM ë¶„ë¥˜ íŒì •"]
        PROMPT["í”„ë¡¬í”„íŠ¸ êµ¬ì¶•<br/>question + choices + candidates"]
        LLM["Gemini API í˜¸ì¶œ<br/>temperature=0.2"]
        PARSE["JSON íŒŒì‹±<br/>+ fallback íŒŒì‹±"]
        VALIDATE["ê²°ê³¼ ê²€ì¦<br/>lecture_id âˆˆ valid_ids?"]
        EVIDENCE["evidence ì •ê·œí™”<br/>_normalize_evidence()"]
        EVID_CHECK{"evidence ìˆìŒ?"}
        FORCE_NO["âŒ no_match = true<br/>lecture_id = null"]
        RESULT["âœ… ë¶„ë¥˜ ê²°ê³¼ ìƒì„±"]
    end
    
    subgraph APPLY["ğŸ“ ê²°ê³¼ ì ìš© (apply_classification_results)"]
        THRESH{"confidence â‰¥ threshold?<br/>(0.7)"}
        DB_WRITE["DB ë°˜ì˜<br/>question.lecture_id = ì„ íƒëœ ê°•ì˜"]
        SUGGEST["ai_suggestedë¡œë§Œ ì €ì¥<br/>(ë¯¸ì ìš©)"]
    end
    
    START --> Q_LOAD --> Q_TEXT
    Q_TEXT --> CACHE --> SCOPE --> BM25 --> AGG
    AGG --> PARENT_CHECK
    PARENT_CHECK -->|"OFF (í˜„ì¬)"| SKIP_EXPAND
    PARENT_CHECK -->|"ON"| UNCERTAIN
    UNCERTAIN -->|"Yes"| EXPAND
    UNCERTAIN -->|"No"| SKIP_EXPAND
    EXPAND --> PROMPT
    SKIP_EXPAND --> PROMPT
    PROMPT --> LLM --> PARSE --> VALIDATE
    VALIDATE --> EVIDENCE --> EVID_CHECK
    EVID_CHECK -->|"ì—†ìœ¼ë©´"| FORCE_NO
    EVID_CHECK -->|"ìˆìœ¼ë©´"| RESULT
    FORCE_NO --> SUGGEST
    RESULT --> THRESH
    THRESH -->|"Yes + apply_mode=all"| DB_WRITE
    THRESH -->|"No"| SUGGEST
```

---

## 2. ê° ë‹¨ê³„ ìƒì„¸ ì„¤ëª…

### 2.1 ì „ì²˜ë¦¬ (Question Text ì¡°í•©)

**íŒŒì¼**: `ai_classifier.py` (ë¼ì¸ 936-945)

```python
question_text = question.content or ""
if choices:
    question_text = f"{question_text}\n" + " ".join(choices)
question_text = question_text.strip()
if len(question_text) > 4000:
    question_text = question_text[:4000]
```

- ë¬¸ì œ ë³¸ë¬¸(`content`)ê³¼ ì„ ì§€(`choices`)ë¥¼ í•©ì³ì„œ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ë¥¼ ë§Œë“¦
- **âš ï¸ ì‹¤íŒ¨ ê°€ëŠ¥ì„±**: `content`ê°€ ì´ë¯¸ì§€ ì „ìš©(`None` ë˜ëŠ” ë¹ˆ ë¬¸ìì—´)ì´ë©´ ê²€ìƒ‰ í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ì–´ì„œ BM25 ê²€ìƒ‰ì´ ì‹¤íŒ¨í•¨

---

### 2.2 Stage 1: RETRIEVE (í›„ë³´ ê°•ì˜ ê²€ìƒ‰)

**íŒŒì¼**: `ai_classifier.py` â†’ `retrieval.py`

í˜„ì¬ Docker ì„¤ì •:
| ì„¤ì • | ê°’ | ì¶œì²˜ |
|------|-----|------|
| `RETRIEVAL_MODE` | `bm25` | `.env.docker` |
| `SEARCH_BACKEND` | `postgres` | `.env.docker` |
| `SEARCH_PG_QUERY_MODE` | `websearch` | `.env.docker` |
| `SEARCH_PG_TRGM_ENABLED` | `0` (OFF) | `.env.docker` |


```mermaid
flowchart TD
    INPUT["question_text ì…ë ¥"]
    
    subgraph TOKENIZE["í† í°í™”"]
        TOKEN["_normalize_query()<br/>í•œê¸€/ì˜ì–´/ìˆ«ì í† í° ì¶”ì¶œ"]
        STOP["ë¶ˆìš©ì–´ ì œê±°<br/>ë‹¤ìŒ, ì¤‘, ì˜³ì€, í‹€ë¦°, ê²ƒ ë“±"]
        BUILD["_build_pg_websearch_query()<br/>Postgres websearch ì¿¼ë¦¬ ìƒì„±"]
    end
    
    subgraph SEARCH["ê²€ìƒ‰ ì‹¤í–‰"]
        PG_SEARCH["_search_chunks_bm25_postgres()<br/>content_tsv @@ websearch_to_tsquery()"]
        FALLBACK1["8-term fallback ì¿¼ë¦¬"]
        FALLBACK2["4-term fallback ì¿¼ë¦¬"]
        TRGM{"TRGM ì¼œì§?<br/>(í˜„ì¬: OFF)"}
    end
    
    subgraph AGGREGATE["Top-K ì§‘ê³„"]
        SCORE["lecture ë³„ ì ìˆ˜ í•©ì‚°"]
        EVID["ê°•ì˜ë‹¹ ìƒìœ„ 3ê°œ evidence"]
        TOP8["ìƒìœ„ 8ê°œ ê°•ì˜ ì„ íƒ"]
    end
    
    INPUT --> TOKEN --> STOP --> BUILD
    BUILD --> PG_SEARCH
    PG_SEARCH -->|"ê²°ê³¼ ì—†ìŒ"| FALLBACK1
    FALLBACK1 -->|"ê²°ê³¼ ì—†ìŒ"| FALLBACK2
    PG_SEARCH -->|"ê²°ê³¼ ìˆìŒ"| TRGM
    FALLBACK1 -->|"ê²°ê³¼ ìˆìŒ"| TRGM
    FALLBACK2 --> TRGM
    TRGM -->|"OFF"| SCORE
    SCORE --> EVID --> TOP8
    
    style TRGM fill:#ff9999
    style PG_SEARCH fill:#ffcc66
```

#### âš ï¸ ì—¬ê¸°ì„œ ì‹¤íŒ¨í•˜ëŠ” ì£¼ìš” ì›ì¸

1. **í† í°ì´ 0ê°œê°€ ë˜ëŠ” ê²½ìš°**: ë¶ˆìš©ì–´ ì œê±° í›„ ì˜ë¯¸ ìˆëŠ” í† í°ì´ ì—†ìœ¼ë©´ ë¹ˆ ì¿¼ë¦¬ â†’ ê²€ìƒ‰ ê²°ê³¼ 0ê±´
2. **Postgres `websearch_to_tsquery` í•œê³„**: CJK(í•œêµ­ì–´) í…ìŠ¤íŠ¸ì— ëŒ€í•´ `simple` configë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ í˜•íƒœì†Œ ë¶„ì„ ì—†ì´ ê³µë°± ë‹¨ìœ„ í† í°ë§Œ ë§¤ì¹­
3. **tsvector ë¯¸ìŠ¤ë§¤ì¹˜**: `lecture_chunks.content_tsv` ì»¬ëŸ¼ì´ ì œëŒ€ë¡œ ì¸ë±ì‹±ë˜ì§€ ì•Šì•˜ê±°ë‚˜, chunk ë‚´ìš©ê³¼ ë¬¸ì œ í…ìŠ¤íŠ¸ì˜ ìš©ì–´ê°€ ë‹¤ë¥´ë©´ ë§¤ì¹­ ì‹¤íŒ¨
4. **TRGMì´ êº¼ì ¸ ìˆìŒ**: ìœ ì‚¬í•œ í‘œí˜„(ì˜¤íƒ€, ë‹¤ë¥¸ í‘œê¸°ë²•)ì´ë©´ ë§¤ì¹­ ë¶ˆê°€ â€” trigram fallbackì´ ë¹„í™œì„±
5. **candidatesê°€ 0ê±´ì´ë©´** â†’ ë°”ë¡œ `no_match=True` ë°˜í™˜ (Stage 3ì„ ê±´ë„ˆëœ€)

---

### 2.3 Stage 2: EXPAND (ì»¨í…ìŠ¤íŠ¸ í™•ì¥)

**íŒŒì¼**: `context_expander.py`, `retrieval_features.py`

```
í˜„ì¬ Docker ì„¤ì •: PARENT_ENABLED = false (ê¸°ë³¸ê°’)
â†’ ì´ ë‹¨ê³„ëŠ” ì™„ì „íˆ ê±´ë„ˆëœ€
```

ì´ ë‹¨ê³„ê°€ ì¼œì ¸ ìˆìœ¼ë©´:
1. `retrieval_features.is_uncertain()` í•¨ìˆ˜ê°€ ê²€ìƒ‰ ê²°ê³¼ì˜ "ë¶ˆí™•ì‹¤ì„±"ì„ í‰ê°€
2. ë¶ˆí™•ì‹¤í•˜ë©´ `expand_candidates()`ë¡œ ê° candidateì˜ seed chunkì—ì„œ BM25 ê¸°ë°˜ semantic neighborsë¥¼ ì¶”ê°€ ìˆ˜ì§‘
3. í™•ì¥ëœ í…ìŠ¤íŠ¸(`parent_text`)ê°€ LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨

---

### 2.4 Stage 3: JUDGE (LLM ë¶„ë¥˜ íŒì •)

**íŒŒì¼**: `ai_classifier.py` GeminiClassifier

```mermaid
flowchart TD
    subgraph PROMPT_BUILD["í”„ë¡¬í”„íŠ¸ êµ¬ì¶•"]
        P1["Question í…ìŠ¤íŠ¸"]
        P2["Choices (ì„ ì§€)"]
        P3["Candidate ì •ë³´<br/>(ID, full_path, evidence snippets)"]
        P4["Instructions<br/>(only pick from candidate IDs)"]
    end
    
    subgraph LLM_CALL["Gemini API í˜¸ì¶œ"]
        API["gemini-3-flash-preview<br/>temp=0.2, response_mime=JSON"]
        RETRY["ìµœëŒ€ 3íšŒ ì¬ì‹œë„<br/>(exponential backoff)"]
    end
    
    subgraph POST_PROCESS["í›„ì²˜ë¦¬ (í•µì‹¬ ê²€ì¦)"]
        JSON_PARSE["JSON íŒŒì‹±<br/>â†’ fallback regex íŒŒì‹±"]
        
        LID_CHECK{"lecture_id<br/>valid_idsì— ìˆìŒ?"}
        LID_NULL["lecture_id = null<br/>no_match = true"]
        
        EVID_NORM["_normalize_evidence()<br/>ì¦ê±° ê²€ì¦"]
        
        VQ_CHECK{"verbatim quote<br/>snippetì— í¬í•¨?"}
        PS_CHECK{"page_start/end<br/>ì¡´ì¬?"}
        CID_CHECK{"chunk_id<br/>candidateì— ìˆìŒ?"}
        
        EVID_PASS["evidence í†µê³¼"]
        EVID_FAIL["evidence ì „ë¶€ ì‹¤íŒ¨"]
        
        FINAL_CHECK{"evidence 1ê°œâ†‘<br/>ë‚¨ì•„ìˆìŒ?"}
        FORCE_NOMATCH["âŒ no_match ê°•ì œ<br/>(grounded evidence ì—†ìŒ)"]
        SUCCESS["âœ… ë¶„ë¥˜ ì„±ê³µ"]
    end
    
    P1 --> API
    P2 --> API
    P3 --> API
    P4 --> API
    API --> RETRY --> JSON_PARSE
    
    JSON_PARSE --> LID_CHECK
    LID_CHECK -->|"ì—†ìŒ"| LID_NULL
    LID_CHECK -->|"ìˆìŒ"| EVID_NORM
    
    EVID_NORM --> VQ_CHECK
    VQ_CHECK -->|"No (í˜„ì¬:í•„ìˆ˜)"| EVID_FAIL
    VQ_CHECK -->|"Yes"| PS_CHECK
    PS_CHECK -->|"No (í˜„ì¬:í•„ìˆ˜)"| EVID_FAIL
    PS_CHECK -->|"Yes"| CID_CHECK
    CID_CHECK -->|"No"| EVID_FAIL
    CID_CHECK -->|"Yes"| EVID_PASS
    
    EVID_PASS --> FINAL_CHECK
    EVID_FAIL --> FINAL_CHECK
    FINAL_CHECK -->|"0ê±´"| FORCE_NOMATCH
    FINAL_CHECK -->|"1ê±´+"| SUCCESS
    
    style FORCE_NOMATCH fill:#ff6666,color:#fff
    style VQ_CHECK fill:#ffaa00
    style PS_CHECK fill:#ffaa00
    style CID_CHECK fill:#ffaa00
```

#### âš ï¸ ì—¬ê¸°ì„œ ì‹¤íŒ¨í•˜ëŠ” ì£¼ìš” ì›ì¸ (ê°€ì¥ ì¤‘ìš”!)

í˜„ì¬ Docker ì„¤ì •:
```
CLASSIFIER_REQUIRE_VERBATIM_QUOTE=1  â† ì—„ê²© ëª¨ë“œ
CLASSIFIER_REQUIRE_PAGE_SPAN=1       â† ì—„ê²© ëª¨ë“œ
```

**`_normalize_evidence()` í•¨ìˆ˜ (ë¼ì¸ 588-664)ì˜ í•„í„°ë§ ë¡œì§:**

| ì¡°ê±´ | ì„¤ì • | ì‹¤íŒ¨ ì‹œ |
|------|------|---------|
| `chunk_id`ê°€ candidateì˜ evidenceì— ì¡´ì¬í•´ì•¼ í•¨ | í•­ìƒ | evidence í•­ëª© ì œê±° |
| LLMì´ ë°˜í™˜í•œ `quote`ê°€ ì›ë³¸ `snippet` ì•ˆì— **ì •í™•íˆ í¬í•¨**ë˜ì–´ì•¼ í•¨ | `REQUIRE_VERBATIM=1` | evidence í•­ëª© ì œê±° |
| `page_start`/`page_end`ê°€ ì¡´ì¬í•´ì•¼ í•¨ | `REQUIRE_PAGE_SPAN=1` | evidence í•­ëª© ì œê±° |

**ğŸ‘‰ evidenceê°€ ëª¨ë‘ í•„í„°ë§ë˜ì–´ 0ê±´ì´ ë˜ë©´ â†’ `no_match=true`ë¡œ ê°•ì œ ë³€í™˜! (ë¼ì¸ 798-801)**

```python
if lecture_id and not no_match:
    evidence = self._normalize_evidence(lecture_id, candidates, evidence_raw)
    if not evidence:
        # No grounded evidence -> force safe no_match.
        lecture_id = None
        no_match = True
```

ì´ê²ƒì´ **"ë‹¹ì—°íˆ ë¶„ë¥˜ë¼ì•¼ í•  ë¬¸ì œê°€ no_matchê°€ ë˜ëŠ”"** ê°€ì¥ í”í•œ ì›ì¸ì…ë‹ˆë‹¤.

---

## 3. í•µì‹¬ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ ì •ë¦¬

```mermaid
flowchart LR
    subgraph FAIL1["ğŸ”´ ì‹¤íŒ¨ 1: ê²€ìƒ‰ ë‹¨ê³„"]
        F1A["í† í°í™” í›„ 0ê±´"]
        F1B["tsvector ë¯¸ë§¤ì¹­"]
        F1C["candidates = 0"]
    end
    
    subgraph FAIL2["ğŸ”´ ì‹¤íŒ¨ 2: Evidence ê²€ì¦"]
        F2A["LLMì´ quoteë¥¼<br/>ì•½ê°„ ë³€í˜•í•´ì„œ ë°˜í™˜"]
        F2B["chunk_idë¥¼<br/>ì˜ëª»ëœ ê°’ìœ¼ë¡œ ë°˜í™˜"]
        F2C["page ì •ë³´<br/>ëˆ„ë½"]
    end
    
    subgraph FAIL3["ğŸ”´ ì‹¤íŒ¨ 3: ID ê²€ì¦"]
        F3A["LLMì´ candidateì— ì—†ëŠ”<br/>lecture_id ë°˜í™˜"]
        F3B["LLMì´ lecture_idë¥¼<br/>ë¬¸ìì—´ë¡œ ë°˜í™˜"]
    end
    
    F1A --> NOMATCH["no_match = true"]
    F1B --> NOMATCH
    F1C --> NOMATCH
    F2A --> NOMATCH
    F2B --> NOMATCH
    F2C --> NOMATCH
    F3A --> NOMATCH
    F3B --> NOMATCH
    
    style NOMATCH fill:#ff4444,color:#fff
```

---

## 4. Docker í™˜ê²½ì˜ í˜„ì¬ ì„¤ì •ê³¼ ì˜í–¥

| í™˜ê²½ë³€ìˆ˜ | í˜„ì¬ê°’ | ì˜í–¥ |
|----------|--------|------|
| `RETRIEVAL_MODE` | `bm25` | embedding ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë§¤ì¹­ë§Œ ì‚¬ìš© |
| `SEARCH_BACKEND` | `postgres` | PostgreSQL `tsvector` ê¸°ë°˜ ê²€ìƒ‰ |
| `SEARCH_PG_QUERY_MODE` | `websearch` | `websearch_to_tsquery('simple', ...)` ì‚¬ìš© |
| `SEARCH_PG_TRGM_ENABLED` | `0` | trigram ìœ ì‚¬ë„ fallback **ë¹„í™œì„±** |
| `CLASSIFIER_REQUIRE_VERBATIM_QUOTE` | `1` | LLM quoteê°€ snippetì— **ì •í™•íˆ** í¬í•¨ë¼ì•¼ í•¨ |
| `CLASSIFIER_REQUIRE_PAGE_SPAN` | `1` | page_start/end **í•„ìˆ˜** |
| `CLASSIFIER_ALLOW_ID_FROM_TEXT` | `0` | reason/study_hintì—ì„œ ID ì¶”ì¶œ **ì•ˆ í•¨** |
| `GEMINI_MODEL_NAME` | `gemini-3-flash-preview` | í”„ë¦¬ë·° ëª¨ë¸ (ì•ˆì •ì„± ë¯¸ë³´ì¥) |

---

## 5. ì½”ë“œ ë””ë²„ê¹… ì§„ì…ì 

í™˜ê²½ë³€ìˆ˜ `CLASSIFIER_DEBUG_LOG=1`ì„ ì¶”ê°€í•˜ë©´ ìƒì„¸ ë¡œê·¸ê°€ ì¶œë ¥ë©ë‹ˆë‹¤:

```bash
# .env.dockerì— ì¶”ê°€
CLASSIFIER_DEBUG_LOG=1
```

ì£¼ìš” ë¡œê·¸ íŠ¸ë ˆì´ìŠ¤ í¬ì¸íŠ¸:

| ë¡œê·¸ í”„ë¦¬í”½ìŠ¤ | ìœ„ì¹˜ | ì •ë³´ |
|--------------|------|------|
| `CLASSIFIER_JOB_ENQUEUED` | line 864 | Job ìƒì„± ì‹œ |
| `CLASSIFIER_JOB_STARTED` | line 893 | Job ì²˜ë¦¬ ì‹œì‘ |
| `CLASSIFIER_PARSE_TRACE` | line 726 | LLM ì‘ë‹µ íŒŒì‹± ê²°ê³¼ |
| `CLASSIFIER_JOB_TRACE` | line 1043 | ë¬¸ì œë³„ ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½ |
| `CLASSIFIER_APPLY_DECISION` | line 1360 | ì ìš© íŒì • ì´ìœ  |
| `CLASSIFIER_APPLY_SKIP` | line 1322 | ìŠ¤í‚µ ì‚¬ìœ  (out_of_candidates) |

---

## 6. ì£¼ìš” ì†ŒìŠ¤ íŒŒì¼ ë§µ

```mermaid
graph TB
    subgraph API["API Layer"]
        ROUTE["routes/manage.py<br/>classify_exam_questions()"]
    end
    
    subgraph Pipeline["Pipeline Layer"]
        PIPELINE["classification_pipeline.py<br/>classify_single_question()"]
        BATCH["ai_classifier.py<br/>AsyncBatchProcessor._process_job()"]
    end
    
    subgraph Services["Service Layer"]
        RETRIEVER["ai_classifier.py<br/>LectureRetriever"]
        CLASSIFIER["ai_classifier.py<br/>GeminiClassifier"]
        RETRIEVAL["retrieval.py<br/>search_chunks_bm25()"]
        EXPANDER["context_expander.py<br/>expand_candidates()"]
        FEATURES["retrieval_features.py<br/>is_uncertain()"]
    end
    
    subgraph Data["Data Layer"]
        DB["PostgreSQL<br/>lecture_chunks.content_tsv"]
        MODELS["models.py<br/>Question, Lecture, LectureChunk"]
    end
    
    subgraph Config["Configuration"]
        ENV[".env.docker"]
        SCHEMA["config/schema.py<br/>ExperimentConfig"]
    end
    
    ROUTE --> BATCH
    PIPELINE --> RETRIEVER
    PIPELINE --> EXPANDER
    PIPELINE --> CLASSIFIER
    BATCH --> RETRIEVER
    BATCH --> CLASSIFIER
    BATCH --> EXPANDER
    RETRIEVER --> RETRIEVAL
    RETRIEVAL --> DB
    EXPANDER --> RETRIEVAL
    CLASSIFIER --> API_CALL["Gemini API"]
    ENV --> SCHEMA
    SCHEMA --> RETRIEVER
    SCHEMA --> CLASSIFIER
    SCHEMA --> RETRIEVAL
```

---

## 7. ê¶Œì¥ í™•ì¸/ìˆ˜ì • í¬ì¸íŠ¸

### ì¦‰ì‹œ í™•ì¸í•  ê²ƒ
1. **`CLASSIFIER_DEBUG_LOG=1`** ì„¤ì • í›„ ë¡œê·¸ì—ì„œ `candidates=0`ì¸ ë¬¸ì œê°€ ìˆëŠ”ì§€ í™•ì¸
2. ë¡œê·¸ì—ì„œ `CLASSIFIER_PARSE_TRACE`ì˜ `no_match` ê°’ í™•ì¸ â€” LLMì´ `no_match=true`ë¥¼ ë°˜í™˜í•˜ëŠ”ì§€, ì•„ë‹ˆë©´ í›„ì²˜ë¦¬ì—ì„œ ê°•ì œ ë³€í™˜ë˜ëŠ”ì§€

### ê°€ì¥ ì˜í–¥ì´ í° ì„¤ì • ë³€ê²½ í›„ë³´
1. **`CLASSIFIER_REQUIRE_VERBATIM_QUOTE=0`**: LLMì´ quoteë¥¼ ì•½ê°„ ë³€í˜•í•´ë„ í—ˆìš© (ê°€ì¥ í° ì˜í–¥)
2. **`CLASSIFIER_REQUIRE_PAGE_SPAN=0`**: page ì •ë³´ ì—†ì–´ë„ evidence í—ˆìš©
3. **`SEARCH_PG_TRGM_ENABLED=1`**: í‘œí˜„ì´ ë‹¤ë¥¸ ê²½ìš°ì—ë„ trigram ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰ ë³´ì™„
4. **`CLASSIFIER_ALLOW_ID_FROM_TEXT=1`**: LLMì´ reason í…ìŠ¤íŠ¸ì— IDë¥¼ ì–¸ê¸‰í–ˆìœ¼ë©´ ì¶”ì¶œ ì‹œë„
